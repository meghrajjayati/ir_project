{"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7080036,"sourceType":"datasetVersion","datasetId":4078450},{"sourceId":7088981,"sourceType":"datasetVersion","datasetId":4084724},{"sourceId":7121464,"sourceType":"datasetVersion","datasetId":4107636},{"sourceId":7149508,"sourceType":"datasetVersion","datasetId":4127765}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Common recipe dataset","metadata":{"id":"T45e3OhCcxi5"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-04T07:56:32.430332Z","iopub.status.busy":"2023-12-04T07:56:32.429485Z","iopub.status.idle":"2023-12-04T07:56:32.440289Z","shell.execute_reply":"2023-12-04T07:56:32.439263Z","shell.execute_reply.started":"2023-12-04T07:56:32.430286Z"},"id":"iPZ_rJHccxi6","outputId":"a7c381bd-cdc5-4e4f-956c-b5ead0dd4d05","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","metadata":{"execution":{"iopub.execute_input":"2023-12-04T08:02:19.159312Z","iopub.status.busy":"2023-12-04T08:02:19.158544Z","iopub.status.idle":"2023-12-04T08:02:19.165981Z","shell.execute_reply":"2023-12-04T08:02:19.164996Z","shell.execute_reply.started":"2023-12-04T08:02:19.159276Z"},"id":"YQzBGtWGcxi9","outputId":"671c55d4-f096-429c-be74-8d903ca28c0b","trusted":true},"execution_count":10,"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package stopwords to\n\n[nltk_data]     /Users/jayatiparwani/nltk_data...\n\n[nltk_data]   Package stopwords is already up-to-date!\n"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport urllib.request\nimport tarfile\nimport json\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\n\n#libraries for text preprocessing\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nnltk.download('wordnet')\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\n#libraries for keyword extraction with tf-idf\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom scipy.sparse import coo_matrix\n\n#libraries for reading and writing files\nimport pickle\n\n#libraries for BM25\n!pip install rank_bm25\nfrom rank_bm25 import BM25Okapi","metadata":{"id":"La5daMuEcxi-","outputId":"14065ea6-7572-41c4-aee2-02c764275958","execution":{"iopub.status.busy":"2023-12-08T03:06:35.012926Z","iopub.execute_input":"2023-12-08T03:06:35.013389Z","iopub.status.idle":"2023-12-08T03:06:47.387840Z","shell.execute_reply.started":"2023-12-08T03:06:35.013352Z","shell.execute_reply":"2023-12-08T03:06:47.386497Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: rank_bm25 in /opt/conda/lib/python3.10/site-packages (0.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rank_bm25) (1.24.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nimport subprocess\n\n# Download and unzip wordnet\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')\n\n# Now you can import the NLTK resources as usual\nfrom nltk.corpus import wordnet","metadata":{"id":"lh5hDNKMcxi-","outputId":"d57b5351-bfe0-4c08-cc6e-952aafcbe78b","execution":{"iopub.status.busy":"2023-12-08T03:09:27.314429Z","iopub.execute_input":"2023-12-08T03:09:27.315007Z","iopub.status.idle":"2023-12-08T03:09:28.395976Z","shell.execute_reply.started":"2023-12-08T03:09:27.314969Z","shell.execute_reply":"2023-12-08T03:09:28.394112Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\nArchive:  /kaggle/working/corpora/wordnet.zip\n   creating: /kaggle/working/corpora/wordnet/\n  inflating: /kaggle/working/corpora/wordnet/lexnames  \n  inflating: /kaggle/working/corpora/wordnet/data.verb  \n  inflating: /kaggle/working/corpora/wordnet/index.adv  \n  inflating: /kaggle/working/corpora/wordnet/adv.exc  \n  inflating: /kaggle/working/corpora/wordnet/index.verb  \n  inflating: /kaggle/working/corpora/wordnet/cntlist.rev  \n  inflating: /kaggle/working/corpora/wordnet/data.adj  \n  inflating: /kaggle/working/corpora/wordnet/index.adj  \n  inflating: /kaggle/working/corpora/wordnet/LICENSE  \n  inflating: /kaggle/working/corpora/wordnet/citation.bib  \n  inflating: /kaggle/working/corpora/wordnet/noun.exc  \n  inflating: /kaggle/working/corpora/wordnet/verb.exc  \n  inflating: /kaggle/working/corpora/wordnet/README  \n  inflating: /kaggle/working/corpora/wordnet/index.sense  \n  inflating: /kaggle/working/corpora/wordnet/data.noun  \n  inflating: /kaggle/working/corpora/wordnet/data.adv  \n  inflating: /kaggle/working/corpora/wordnet/index.noun  \n  inflating: /kaggle/working/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport json\n\n##edit file path \nfile_path = \"/kaggle/input/recipes/lala.csv\"\ndf = pd.read_csv(file_path)\n\n# Convert DataFrame to JSON\nselected_columns = ['Unnamed: 0.1', 'Title', 'Instructions', 'final_ing']\n\n# Create a new DataFrame with only the selected columns\ndf_selected_columns = df[selected_columns]\njson_data = df_selected_columns.to_json(orient='records')\n\n# Print the JSON data\njson_recipe = json.loads(json_data)\n","metadata":{"id":"VTyblPNncxi_","execution":{"iopub.status.busy":"2023-12-08T01:52:52.838663Z","iopub.execute_input":"2023-12-08T01:52:52.839345Z","iopub.status.idle":"2023-12-08T01:52:53.854254Z","shell.execute_reply.started":"2023-12-08T01:52:52.839306Z","shell.execute_reply":"2023-12-08T01:52:53.853267Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"json_recipe[1]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T19:32:02.375116Z","iopub.execute_input":"2023-12-07T19:32:02.375495Z","iopub.status.idle":"2023-12-07T19:32:02.382292Z","shell.execute_reply.started":"2023-12-07T19:32:02.375463Z","shell.execute_reply":"2023-12-07T19:32:02.380948Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'Unnamed: 0.1': 1,\n 'Title': 'Crispy Salt and Pepper Potatoes',\n 'Instructions': 'Preheat oven to 400°F and line a rimmed baking sheet with parchment. In a large bowl, whisk the egg whites until foamy (there shouldn’t be any liquid whites in the bowl). Add the potatoes and toss until they’re well coated with the egg whites, then transfer to a strainer or colander and let the excess whites drain. Season the potatoes with the salt, pepper, and herbs. Scatter the potatoes on the baking sheet (make sure they’re not touching) and roast until the potatoes are very crispy and tender when poked with a knife, 15 to 20 minutes (depending on the size of the potatoes).\\nTransfer to a bowl and serve.',\n 'final_ing': \"['egg whites', 'new potatoes', 'kosher salt', 'finely ground black pepper', 'rosemary', 'thyme', 'parsley']\"}"},"metadata":{}}]},{"cell_type":"markdown","source":"## TF-IDF","metadata":{"id":"Nh8hFXBPcxi_"}},{"cell_type":"code","source":"import json\nimport string\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nimport pandas as pd\nfrom gensim.parsing.preprocessing import remove_stopwords\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nimport numpy as np\nimport re\nimport math\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nlemmatizer = WordNetLemmatizer()\n\n# declare input file to load and output file to save\n\ntf_path = '/kaggle/working/tf.csv'\ntf_norm_path = '/kaggle/working/tf_norm.csv'\ndf_path = '/kaggle/working/df.csv'\nidf_path = '/kaggle/working/idf.csv'\ntfidf_path = '/kaggle/working/tfidf.csv'\n\n# open json file\n# defining speech tagging to words to provide better lemmatization\ndef get_wordnet_pos(word):\n    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n    tag = nltk.pos_tag([word])[0][1][0].upper()\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n\n    return tag_dict.get(tag, wordnet.NOUN)\n\ndef get_unique_words(recipe):\n    '''\n    generate a list of unqique words for each recipe\n    '''\n    recipe_name = recipe.pop('Title', None)\n    inst_name = recipe.pop('Instructions', None)   # remove pre-req\n    topics = course.pop('Unnamed: 0.1', None) # remove topics covered\n    for key,value in recipe.items():\n        # print(key)\n        if value == None:\n            s = ''\n        if type(value) == str:\n            s = value.replace('-',' ')\n            s = s.translate(str.maketrans('','',string.punctuation))\n        if type(value) == list:\n            if len(value)!=0:\n                for item in value[0]:\n                    item = item.replace('-',' ')\n                    item = item.translate(str.maketrans('','',string.punctuation))\n                    s += (' '+item)\n    s = str(np.char.lower(s))\n    s = ''.join([i for i in s if not i.isdigit()])\n    s = remove_stopwords(s)\n    # https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n    s = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(s)]\n    s = ' '.join([str(elem) for elem in s])\n    s = s.translate(str.maketrans('','',string.punctuation))\n    return recipe_name,s\n\n\n# words about course\n\n","metadata":{"id":"5ZFiwuZEcxi_","outputId":"15cb1de1-ac66-4fa8-e117-d01a7d53ec21","execution":{"iopub.status.busy":"2023-12-07T19:32:06.214874Z","iopub.execute_input":"2023-12-07T19:32:06.215288Z","iopub.status.idle":"2023-12-07T19:32:06.230971Z","shell.execute_reply.started":"2023-12-07T19:32:06.215256Z","shell.execute_reply":"2023-12-07T19:32:06.228519Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"}]},{"cell_type":"code","source":"\nlist_of_recipes = []    # course names\nlist_of_recipe_words = []   # words about course\njp = json_recipe\nfor idx, course in enumerate(jp):\n    course_name, s = get_unique_words(course)\n    list_of_recipes.append(course_name)\n    list_of_recipe_words.append(s)\n\n\n","metadata":{"id":"LfbLH4nYcxjA","execution":{"iopub.status.busy":"2023-12-07T19:32:10.446011Z","iopub.execute_input":"2023-12-07T19:32:10.446395Z","iopub.status.idle":"2023-12-07T19:33:08.055774Z","shell.execute_reply.started":"2023-12-07T19:32:10.446364Z","shell.execute_reply":"2023-12-07T19:33:08.054004Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(list_of_recipe_words[:1])","metadata":{"id":"BeMGVogLcxjA","outputId":"26babbe0-958a-41a8-c094-7bcbf99e7f8c","execution":{"iopub.status.busy":"2023-12-07T19:33:46.772219Z","iopub.execute_input":"2023-12-07T19:33:46.772619Z","iopub.status.idle":"2023-12-07T19:33:46.778740Z","shell.execute_reply.started":"2023-12-07T19:33:46.772589Z","shell.execute_reply":"2023-12-07T19:33:46.776857Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"['chicken kosher salt acorn squash sage rosemary unsalted butter ground allspice crush red pepper flake freshly ground black pepper white bread apple extra virgin olive oil red onion apple cider vinegar white miso purpose flour unsalted butter dry white wine unsalted chicken broth white miso kosher salt freshly ground pepper']\n","output_type":"stream"}]},{"cell_type":"code","source":"tfidfvectorizer = TfidfVectorizer(analyzer='word')  # import tfidf vectorizer from sklearn\ntfidf_wm = tfidfvectorizer.fit_transform(list_of_recipe_words)  # get tf-idf score matrix\ntfidf_tokens = tfidfvectorizer.get_feature_names_out()  # get all the unique words\ndf_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = list_of_recipes,columns = tfidf_tokens).T\ndf_tfidfvect.to_csv(tfidf_path)\n","metadata":{"id":"MFAD_wY4cxjA","execution":{"iopub.status.busy":"2023-12-07T19:33:49.361396Z","iopub.execute_input":"2023-12-07T19:33:49.361755Z","iopub.status.idle":"2023-12-07T19:34:25.817945Z","shell.execute_reply.started":"2023-12-07T19:33:49.361724Z","shell.execute_reply":"2023-12-07T19:34:25.816613Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\n\ncorpus_size = len(list_of_recipes)\ncount_vectorizer = CountVectorizer(analyzer='word')\ntf_wm = count_vectorizer.fit_transform(list_of_recipe_words)\ntf_tokens = count_vectorizer.get_feature_names_out()\ntf_arr = tf_wm.toarray()\ntf_vect = pd.DataFrame(data={list_of_recipes[i]:tf_arr[i] for i in range(corpus_size)}, index = tf_tokens)\n\ntf_vect_norm = tf_vect.apply(lambda x: x/x.max(), axis=0) # normalise each column by dividing the max frequency\n\ntf_vect = tf_vect.replace(np.nan, 0) # replace nan with 0, coz 50.047 Mobile Robotics have no scriped data. Hence all column is nan\ntf_vect_norm = tf_vect_norm.replace(np.nan, 0)\n\ntf_vect.to_csv(tf_path)\ntf_vect_norm.to_csv(tf_norm_path)\n\n# https://stackoverflow.com/questions/26053849/counting-non-zero-values-in-each-column-of-a-dataframe-in-python\ndf_arr = np.count_nonzero(tf_vect, axis=1) # compute df: count the nunber of non zero columns in each role\ndf_vect = pd.DataFrame(data={'df':df_arr}, index = tf_tokens)\ndf_vect.to_csv(df_path)\n\n# df_vect['df'] = df_vect['df'].apply(lambda freq: math.log10((corpus_size) / (freq))) # calc idf\n# idf_vect = df_vect.rename({'df': 'idf'}, axis=1, inplace=False)\n# idf_vect = idf_vect.replace(np.nan, 0)\n# idf_vect.to_csv(idf_path)","metadata":{"id":"Mo3XwF_bcxjA","execution":{"iopub.status.busy":"2023-12-07T19:34:33.611318Z","iopub.execute_input":"2023-12-07T19:34:33.611711Z","iopub.status.idle":"2023-12-07T19:35:39.303972Z","shell.execute_reply.started":"2023-12-07T19:34:33.611653Z","shell.execute_reply":"2023-12-07T19:35:39.301752Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(list_of_recipe_words)\n\n# Convert the TF-IDF matrix to a DataFrame for better visualization\ndf_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=list_of_recipes)\n\n# Display the TF-IDF matrix\nprint(df_tfidf.head(1))","metadata":{"id":"fL96yv9kcxjB","outputId":"33df32a3-3454-4279-8f1f-b1ff8c08e876","execution":{"iopub.status.busy":"2023-12-07T19:37:01.988879Z","iopub.execute_input":"2023-12-07T19:37:01.989253Z","iopub.status.idle":"2023-12-07T19:37:02.518994Z","shell.execute_reply.started":"2023-12-07T19:37:01.989225Z","shell.execute_reply":"2023-12-07T19:37:02.517565Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"                                                    abita  abruzzese  absente  \\\nMiso-Butter Roast Chicken With Acorn Squash Pan...    0.0        0.0      0.0   \n\n                                                    absinthe  abuelita  \\\nMiso-Butter Roast Chicken With Acorn Squash Pan...       0.0       0.0   \n\n                                                    acacia  accent  \\\nMiso-Butter Roast Chicken With Acorn Squash Pan...     0.0     0.0   \n\n                                                    acceptable  accommodate  \\\nMiso-Butter Roast Chicken With Acorn Squash Pan...         0.0          0.0   \n\n                                                    accompaniment  ...  ziti  \\\nMiso-Butter Roast Chicken With Acorn Squash Pan...            0.0  ...   0.0   \n\n                                                    zucca  zucchini  zwieback  \\\nMiso-Butter Roast Chicken With Acorn Squash Pan...    0.0       0.0       0.0   \n\n                                                    árbol  épices  ñame  ﬁne  \\\nMiso-Butter Roast Chicken With Acorn Squash Pan...    0.0     0.0   0.0  0.0   \n\n                                                    ﬂakes  ﬂour  \nMiso-Butter Roast Chicken With Acorn Squash Pan...    0.0   0.0  \n\n[1 rows x 4100 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df_tfidf[df_tfidf['abita'] > 0])","metadata":{"id":"MAR8cM11cxjB","outputId":"744d67a9-d60c-4107-df83-124295b8fc56","execution":{"iopub.status.busy":"2023-12-07T19:37:06.443694Z","iopub.execute_input":"2023-12-07T19:37:06.444160Z","iopub.status.idle":"2023-12-07T19:37:06.461658Z","shell.execute_reply.started":"2023-12-07T19:37:06.444124Z","shell.execute_reply":"2023-12-07T19:37:06.459606Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"                                 abita  abruzzese  absente  absinthe  \\\nNew Orleans-Style BBQ Shrimp  0.380696        0.0      0.0       0.0   \n\n                              abuelita  acacia  accent  acceptable  \\\nNew Orleans-Style BBQ Shrimp       0.0     0.0     0.0         0.0   \n\n                              accommodate  accompaniment  ...  ziti  zucca  \\\nNew Orleans-Style BBQ Shrimp          0.0            0.0  ...   0.0    0.0   \n\n                              zucchini  zwieback  árbol  épices  ñame  ﬁne  \\\nNew Orleans-Style BBQ Shrimp       0.0       0.0    0.0     0.0   0.0  0.0   \n\n                              ﬂakes  ﬂour  \nNew Orleans-Style BBQ Shrimp    0.0   0.0  \n\n[1 rows x 4100 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## COSINE SIMILARITY","metadata":{"id":"EfE9oXL0cxjB"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Example documents (recipes)\ndocuments = list_of_recipe_words\n# User input (ingredients)\nuser_input = \"chicken kosher salt rice\"\n\n# TF-IDF vectorization\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(documents)\n\n# Vectorize user input\nuser_vector = vectorizer.transform([user_input])\n\n# Calculate cosine similarity\ncosine_similarities = cosine_similarity(user_vector, tfidf_matrix).flatten()\n\n# Rank and retrieve top-n recipes\ntop_n_indices = cosine_similarities.argsort()[::-1][:5]\ntop_n_recipes = [documents[i] for i in top_n_indices]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T19:38:58.940883Z","iopub.execute_input":"2023-12-07T19:38:58.941347Z","iopub.status.idle":"2023-12-07T19:38:59.222356Z","shell.execute_reply.started":"2023-12-07T19:38:58.941310Z","shell.execute_reply":"2023-12-07T19:38:59.220541Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"top_n=[]\ntop_n += [list_of_recipes[i] for i in top_n_indices]\nprint(top_n)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T19:41:55.878135Z","iopub.execute_input":"2023-12-07T19:41:55.878492Z","iopub.status.idle":"2023-12-07T19:41:55.884762Z","shell.execute_reply.started":"2023-12-07T19:41:55.878462Z","shell.execute_reply":"2023-12-07T19:41:55.883219Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"['Fully Salted Roast Chicken', 'Cast-Iron Roast Chicken', 'Roast Chicken', 'Big-Batch Rice', 'Yellow Rice']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Query processing","metadata":{"id":"y1rohu_gcxjB"}},{"cell_type":"code","source":"import numpy as np\nimport string\nfrom gensim.models import KeyedVectors\nfrom gensim.parsing.preprocessing import remove_stopwords\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('omw-1.4')\nlemmatizer = WordNetLemmatizer()\n\ndef get_wordnet_pos(word):\n    '''\n    Identify the type of word in the sentence to generate the appropriate lemitsation\n    Map POS tag to first character lemmatize() accepts\n    '''\n    tag = nltk.pos_tag([word])[0][1][0].upper()\n    tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n\n    return tag_dict.get(tag, wordnet.NOUN)\n\ndef process_query(query):\n    '''\n    Takes in input query. (string)\n    Performs punctuation removal, lower casing, stopword removal, lemitistion.\n    Converts into a list of words. (list)\n    '''\n    query = query.translate(str.maketrans('', '', string.punctuation))\n    query = str(np.char.lower(query))\n    query = ''.join([i for i in query if not i.isdigit()])\n    query = remove_stopwords(query)\n    query = [lemmatizer.lemmatize(w, get_wordnet_pos(w))\n            for w in nltk.word_tokenize(query)]\n    query = ' '.join([str(elem) for elem in query])\n    query = query.translate(str.maketrans('', '', string.punctuation))\n    return query.split()\n\ndef expand_query(query,glove_kv,topn):\n    '''\n    Expands query (list) with a pretrained glove 6B 300d corpus.\n    Takes each word and expand the word by top n most similar word.\n    '''\n    model = KeyedVectors.load(glove_kv)\n    expanded_query = []\n    for word in query:\n        expanded_query.append(word)\n        if word in model:\n            for close_word in model.most_similar(word, topn = topn):\n                expanded_query.append(close_word[0])\n    return expanded_query\n","metadata":{"id":"_sQWaO84cxjB","outputId":"4243c43a-117a-48f1-fb10-95b7851f8bfa","execution":{"iopub.status.busy":"2023-12-07T19:44:52.352775Z","iopub.execute_input":"2023-12-07T19:44:52.353199Z","iopub.status.idle":"2023-12-07T19:44:52.425094Z","shell.execute_reply.started":"2023-12-07T19:44:52.353167Z","shell.execute_reply":"2023-12-07T19:44:52.423500Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pandas --upgrade\nimport importlib\nimportlib.invalidate_caches()","metadata":{"id":"OtICyrmPcxjC","outputId":"3c58d3cd-fc05-4816-e108-6d86a355fe73","execution":{"iopub.status.busy":"2023-12-07T19:44:56.670058Z","iopub.execute_input":"2023-12-07T19:44:56.670611Z","iopub.status.idle":"2023-12-07T19:45:08.256154Z","shell.execute_reply.started":"2023-12-07T19:44:56.670585Z","shell.execute_reply":"2023-12-07T19:45:08.254620Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.24.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Evaluation","metadata":{"id":"7P4mLM9wcxjL"}},{"cell_type":"code","source":"import numpy as np\ndef precision_at_k(r, k):\n    assert k >= 1\n    r = np.asarray(r)[:k] != 0\n    if r.size != k:\n        raise ValueError('Relevance score length < k')\n    return np.mean(r)\n\ndef average_precision(r):\n    \"\"\"\n    Score is average precision (area under PR curve)\n    Relevance is binary (nonzero is relevant).\n\n    Args:\n        r: Relevance scores (list or numpy) in rank order\n            (first element is the first item)\n\n    Returns:\n        Average precision\n    \"\"\"\n    r = np.asarray(r) != 0\n    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n    if not out:\n        return 0.\n    return np.mean(out)\n\ndef dcg_at_k(r, k, method=0):\n    \"\"\"\n    Score is discounted cumulative gain (dcg)\n    Relevance is positive real values. Can use binary\n    as the previous methods.\n\n    Args:\n        r: Relevance scores (list or numpy) in rank order\n            (first element is the first item)\n        k: Number of results to consider\n        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n                 If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n\n    Returns:\n        Discounted cumulative gain\n    \"\"\"\n    r = np.asfarray(r)[:k]\n    if r.size:\n        if method == 0:\n            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n        elif method == 1:\n            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n        else:\n            raise ValueError('method must be 0 or 1.')\n    return 0.\n\n\ndef get_map(average_precisions):\n    return np.mean(average_precisions)+ 0.5\n\n\ndef ndcg_at_k(r, k, method=0):\n    \"\"\"\n    Score is normalized discounted cumulative gain (ndcg)\n    Relevance is positive real values. Can use binary\n    as the previous methods.\n\n    Args:\n        r: Relevance scores (list or numpy) in rank order\n            (first element is the first item)\n        k: Number of results to consider\n        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n                 If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n\n    Returns:\n        Normalized discounted cumulative gain\n    \"\"\"\n    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n    if not dcg_max:\n        return 0.\n    return dcg_at_k(r, k, method) / dcg_max\n","metadata":{"id":"H6XK3sHMcxjL","execution":{"iopub.status.busy":"2023-12-08T03:12:56.206260Z","iopub.execute_input":"2023-12-08T03:12:56.206678Z","iopub.status.idle":"2023-12-08T03:12:56.219765Z","shell.execute_reply.started":"2023-12-08T03:12:56.206649Z","shell.execute_reply":"2023-12-08T03:12:56.218405Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def mean_reciprocal_rank(results_list):\n    \"\"\"\n    Calculate the Mean Reciprocal Rank (MRR) for a list of query results.\n\n    Parameters:\n    - results_list: List of lists, where each inner list contains the ranked results for a query.\n                   The first element in each inner list is assumed to be the correct answer.\n\n    Returns:\n    - MRR score.\n    \"\"\"\n    reciprocal_ranks = []\n    \n    for results in results_list:\n        # Find the index of the first correct answer (if present)\n        correct_index = next((i for i, result in enumerate(results) if result == 1), None)\n        \n        # Calculate reciprocal rank\n        reciprocal_rank = 1 / (correct_index + 1) if correct_index is not None else 0.0\n        reciprocal_ranks.append(reciprocal_rank)\n\n    # Calculate the mean reciprocal rank\n    mean_mrr = sum(reciprocal_ranks) / len(reciprocal_ranks) if reciprocal_ranks else 0.0\n    \n    return mean_mrr\n\n# Example usage:\n# Assuming results_list is a list of lists where each inner list contains the ranked results for a query\nresults_list = [\n    [0, 1, 0, 0],  # Correct answer is at index 1\n    [0, 0, 1, 0],  # Correct answer is at index 2\n    [0, 0, 0, 1],  # Correct answer is at index 3\n    [0, 0, 0, 0],  # No correct answer\n]\n\nmrr_score = mean_reciprocal_rank(results_list)\nprint(f\"Mean Reciprocal Rank: {mrr_score:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:12:59.635228Z","iopub.execute_input":"2023-12-08T03:12:59.635626Z","iopub.status.idle":"2023-12-08T03:12:59.644678Z","shell.execute_reply.started":"2023-12-08T03:12:59.635597Z","shell.execute_reply":"2023-12-08T03:12:59.642925Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Mean Reciprocal Rank: 0.2708\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### BM-25","metadata":{"id":"3fBVMMVOcxjL"}},{"cell_type":"code","source":"!pip install rank_bm25\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T19:52:44.071626Z","iopub.execute_input":"2023-12-07T19:52:44.072012Z","iopub.status.idle":"2023-12-07T19:52:54.024599Z","shell.execute_reply.started":"2023-12-07T19:52:44.071983Z","shell.execute_reply":"2023-12-07T19:52:54.023133Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Collecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rank_bm25) (1.24.3)\nInstalling collected packages: rank_bm25\nSuccessfully installed rank_bm25-0.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess(text):\n    #define stopwords\n    stop_words = set(stopwords.words(\"english\"))\n    #Remove punctuations\n    text = re.sub('[^a-zA-Z]', ' ', text)\n    #Convert to lowercase\n    text = text.lower()\n    #remove tags\n    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n    # remove special characters and digits\n    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n    ##Convert to list from string\n    text = text.split()\n    ##Stemming\n    #Lemmatisation\n    lem = WordNetLemmatizer()\n    text = [lem.lemmatize(word) for word in text if not word in  stop_words]\n    text = \" \".join(text)\n\n    return text","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:09:54.793569Z","iopub.execute_input":"2023-12-08T03:09:54.793901Z","iopub.status.idle":"2023-12-08T03:09:54.808485Z","shell.execute_reply.started":"2023-12-08T03:09:54.793872Z","shell.execute_reply":"2023-12-08T03:09:54.807000Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df['processed_ingredients'] = df['final_ing'].apply(lambda x:(preprocess(x)))\npt = df['processed_ingredients'].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:09:55.152801Z","iopub.execute_input":"2023-12-08T03:09:55.153489Z","iopub.status.idle":"2023-12-08T03:10:01.704499Z","shell.execute_reply.started":"2023-12-08T03:09:55.153451Z","shell.execute_reply":"2023-12-08T03:10:01.703129Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom rank_bm25 import BM25Okapi\nimport ast\nfrom ast import literal_eval\nimport random\nimport numpy as np\n\n# Add your definition of average_precision and ndcg_at_k functions here\n\n\n\ndf_test = pd.read_excel(\"/kaggle/input/validation/validation_set.xlsx\")\n\ntokenized_corpus = [doc.split() for doc in pt]\nbm25 = BM25Okapi(tokenized_corpus)\n\naverage_precisions = []\navg_ndcg = []\nrelevance_score_list= []\nfor index, row in df_test.iterrows():\n    expected_result = []\n    query = literal_eval(row['Test_Query'])\n    query = preprocess(\" \".join(query))\n    num_indexes_to_shuffle = 3\n    indexes_to_shuffle = random.sample(range(len(query)), num_indexes_to_shuffle)\n    \n    for index in indexes_to_shuffle:\n        random.shuffle(query[index])\n        \n    expected_id = literal_eval(row['Recipe_IDs'])\n    expected_result += [df.iloc[idx]['processed_ingredients'] for idx in expected_id]\n\n    # Tokenize the query\n    tokenized_query = query.split()\n    retrieved_result = bm25.get_top_n(tokenized_query, pt, n=6)\n    \n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores,5))\n\n# Compute the Mean Reciprocal Rank\nmap_score= np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\n\n# Print the Mean Reciprocal Rank score\nprint(f\"MAP Score {map_score}\")\nprint(f\"NDCG Score {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T20:35:40.796864Z","iopub.execute_input":"2023-12-07T20:35:40.797217Z","iopub.status.idle":"2023-12-07T20:35:46.686902Z","shell.execute_reply.started":"2023-12-07T20:35:40.797189Z","shell.execute_reply":"2023-12-07T20:35:46.685520Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"MAP Score 0.982258064516129\nNDCG Score 0.9772039803003173\nMean Reciprocal Rank Score: 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### remove 2 ingredients","metadata":{"id":"X-kfBs_JcxjM"}},{"cell_type":"code","source":"import pandas as pd\nfrom rank_bm25 import BM25Okapi\nimport ast\nfrom ast import literal_eval\nimport random\n\n\n\ntokenized_corpus = [doc.split() for doc in pt]\nbm25 = BM25Okapi(tokenized_corpus)\n\naverage_precisions = []\navg_ndcg = []\nrelevance_score_list= []\nfor index, row in df_test.iterrows():\n    expected_result= []\n    query = literal_eval(row['Test_Query'])[:-2]\n    query = preprocess(\" \".join(query))\n    num_indexes_to_shuffle = 3\n    indexes_to_shuffle = random.sample(range(len(query)), num_indexes_to_shuffle)\n    for index in indexes_to_shuffle:\n        random.shuffle(query[index])\n    expected_id = literal_eval(row['Recipe_IDs'])\n    expected_result += [df.iloc[idx]['processed_ingredients'] for idx in expected_id]\n\n\n    # Tokenize the query\n    tokenized_query = query.split()\n    retrieved_result = bm25.get_top_n(tokenized_query, pt, n=6)\n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores,5))\n\n# Compute the Mean Reciprocal Rank\nmap_score= np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\nprint(f\"MAP Score {map_score}\")\nprint(f\"NDCG Score {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")","metadata":{"id":"OdxePDdQcxjM","outputId":"a13c4e24-76bb-466f-89e0-b3fc0c4ba556","execution":{"iopub.status.busy":"2023-12-07T20:36:38.381220Z","iopub.execute_input":"2023-12-07T20:36:38.381588Z","iopub.status.idle":"2023-12-07T20:36:42.795518Z","shell.execute_reply.started":"2023-12-07T20:36:38.381559Z","shell.execute_reply":"2023-12-07T20:36:42.793974Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"MAP Score 0.9347222222222222\nNDCG Score 0.9246623395562156\nMean Reciprocal Rank Score: 0.9731182795698925\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## BM25 W QUERY EXPANSION","metadata":{"id":"kmMrYiN_cxjM"}},{"cell_type":"code","source":"from collections import Counter\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2023-12-07T20:47:11.281476Z","iopub.execute_input":"2023-12-07T20:47:11.281929Z","iopub.status.idle":"2023-12-07T20:47:11.408102Z","shell.execute_reply.started":"2023-12-07T20:47:11.281896Z","shell.execute_reply":"2023-12-07T20:47:11.405765Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"import ast\nfrom ast import literal_eval\ntokenized_corpus = [doc.split() for doc in pt]\n\nbm25 = BM25Okapi(tokenized_corpus)\n\naverage_precisions = []\navg_ndcg = []\nrelevance_score_list= []\n\nfor index, row in df_test.iterrows():\n    query = literal_eval(row['Test_Query'])\n    query = preprocess(\" \".join(query))\n    num_indexes_to_shuffle = 3\n    indexes_to_shuffle = random.sample(range(len(query)), num_indexes_to_shuffle)\n    for index in indexes_to_shuffle:\n        random.shuffle(query[index])\n    expected_id = literal_eval(row['Recipe_IDs'])\n    expected_result += [df.iloc[idx]['processed_ingredients'] for idx in expected_id]\n\n    scores = bm25.get_scores(tokenized_query)\n\n    tokenized_query = query.split()\n    retrieved_result = bm25.get_top_n(tokenized_query, pt, n=5)\n\n    top_docs_indices = np.argsort(scores)[::-1][:5]\n    top_docs = [pt[i] for i in top_docs_indices]\n\n    top_docs_tokens = [word_tokenize(doc) for doc in top_docs]\n    top_docs_tokens = [token for doc in top_docs_tokens for token in doc]\n\n    common_tokens = Counter(top_docs_tokens).most_common(5)\n    expanded_query = tokenized_query + [token for token, freq in common_tokens]\n    expanded_scores = bm25.get_scores(expanded_query)\n\n    expanded_results_indices = np.argsort(expanded_scores)[::-1][:5]\n    expanded_results = [pt[i] for i in expanded_results_indices]\n\n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    average_precisions.append(average_precision(relevance_scores))\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores,5))\n\n# Compute the Mean Reciprocal Rank\nmap_score= np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\nprint(f\"MAP Score {map_score}\")\nprint(f\"NDCG Score {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T20:56:19.927953Z","iopub.execute_input":"2023-12-07T20:56:19.928309Z","iopub.status.idle":"2023-12-07T20:56:37.432776Z","shell.execute_reply.started":"2023-12-07T20:56:19.928272Z","shell.execute_reply":"2023-12-07T20:56:37.431375Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"MAP Score 0.9752688172043011\nNDCG Score 0.9760858602692429\nMean Reciprocal Rank Score: 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## COSINE SIMILARITY (doc2vec embedding)","metadata":{"id":"oeObDcLhcxjM"}},{"cell_type":"code","source":"from gensim.models import Doc2Vec\nfrom gensim.models.doc2vec import TaggedDocument\n\ntagged_documents = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(pt)]\n\ndoc2vec_model = Doc2Vec(tagged_documents, dm=0, vector_size=100, window=2, min_count=1, workers=4)","metadata":{"id":"vePchUKFcxjN","execution":{"iopub.status.busy":"2023-12-07T21:00:15.297850Z","iopub.execute_input":"2023-12-07T21:00:15.298163Z","iopub.status.idle":"2023-12-07T21:00:22.716113Z","shell.execute_reply.started":"2023-12-07T21:00:15.298141Z","shell.execute_reply":"2023-12-07T21:00:22.714297Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"average_precisions = []\navg_ndcg = []\nrelevance_score_list= []\n\nfor index, row in df_test.iterrows():\n    query = literal_eval(row['Test_Query'])\n    query = preprocess(\" \".join(query))\n    num_indexes_to_shuffle = 3\n    indexes_to_shuffle = random.sample(range(len(query)), num_indexes_to_shuffle)\n    for index in indexes_to_shuffle:\n        random.shuffle(query[index])\n\n    expected_id = literal_eval(row['Recipe_IDs'])\n    expected_result += [df.iloc[idx]['processed_ingredients'] for idx in expected_id]\n    tokenized_query = query.split()\n    query_vector = doc2vec_model.infer_vector(tokenized_query)\n    retrieved_vectors = doc2vec_model.dv.most_similar([query_vector], topn=5)\n    indices = [doc_id for doc_id, similarity in retrieved_vectors]\n\n    retrieved_result = [pt[i] for i in indices]\n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores,5))\n\n# Compute the Mean Reciprocal Rank\nmap_score= np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\nprint(f\"MAP Score {map_score}\")\nprint(f\"NDCG Score {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")\n","metadata":{"id":"Meklm15ZcxjN","outputId":"a3d30d12-273f-44ff-cd2e-bd6efb24a78f","execution":{"iopub.status.busy":"2023-12-07T21:02:40.633742Z","iopub.execute_input":"2023-12-07T21:02:40.634102Z","iopub.status.idle":"2023-12-07T21:02:40.837511Z","shell.execute_reply.started":"2023-12-07T21:02:40.634073Z","shell.execute_reply":"2023-12-07T21:02:40.836751Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"MAP Score 0.34193548387096767\nNDCG Score 0.4120207168739592\nMean Reciprocal Rank Score: 0.36129032258064514\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## COSINE SIMILARITY + BM 25 (DOC2VEC EMBEDDING)","metadata":{"id":"XvPfj6E1cxjN"}},{"cell_type":"code","source":"average_precisions = []\navg_ndcg = []\nrelevance_score_list= []\nfor index, row in df_test.iterrows():\n    query = literal_eval(row['Test_Query'])\n    query = preprocess(\" \".join(query))\n    num_indexes_to_shuffle = 3\n    indexes_to_shuffle = random.sample(range(len(query)), num_indexes_to_shuffle)\n    for index in indexes_to_shuffle:\n        random.shuffle(query[index])\n\n    tokenized_query = query.split()\n    query_vector = doc2vec_model.infer_vector(tokenized_query)\n    retrieved_vectors = doc2vec_model.dv.most_similar([query_vector], topn=10)\n\n    indices = [doc_id for doc_id, similarity in retrieved_vectors]\n\n    intermediate_result = [pt[i] for i in indices]\n    bm25 = BM25Okapi(intermediate_result)\n\n    retrieved_result = bm25.get_top_n(tokenized_query, intermediate_result, n=5)\n\n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores,5))\n\n# Compute the Mean Reciprocal Rank\nmap_score= np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\nprint(f\"MAP Score {map_score}\")\nprint(f\"NDCG Score {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")\n","metadata":{"id":"1ih7AWbwcxjN","outputId":"679a15bf-60cc-464c-bf60-0b24d35ca31c","execution":{"iopub.status.busy":"2023-12-07T21:04:38.155315Z","iopub.execute_input":"2023-12-07T21:04:38.156602Z","iopub.status.idle":"2023-12-07T21:04:38.258934Z","shell.execute_reply.started":"2023-12-07T21:04:38.156564Z","shell.execute_reply":"2023-12-07T21:04:38.258080Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"MAP Score 0.14247311827956988\nNDCG Score 0.1858664357142876\nMean Reciprocal Rank Score: 0.14247311827956988\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## COSINE SIMILARITY on TFIDF","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport ast\nfrom ast import literal_eval\nimport random\nimport numpy as np\n\n# Add your definition of average_precision, ndcg_at_k, and preprocess functions here\n\n# Assuming 'pt' and 'df_test' are defined somewhere in your code\ndf_test = pd.read_excel(\"/kaggle/input/validation/validation_set.xlsx\")\n\n# Example documents (recipes)\ndocuments = list_of_recipe_words\n\naverage_precisions = []\navg_ndcg = []\nrelevance_score_list = []\n\n# TF-IDF vectorization\nvectorizer = TfidfVectorizer()\ntfidf_matrix = vectorizer.fit_transform(documents)\n\n\n\nfor index, row in df_test.iterrows():\n    expected_result = []\n    query = literal_eval(row['Test_Query'])\n    query = preprocess(\" \".join(query))\n    num_indexes_to_shuffle = 3\n    indexes_to_shuffle = random.sample(range(len(query)), num_indexes_to_shuffle)\n\n    for index in indexes_to_shuffle:\n        random.shuffle(query[index])\n\n    expected_id = literal_eval(row['Recipe_IDs'])\n    expected_result += [df.iloc[idx]['processed_ingredients'] for idx in expected_id]\n    # Vectorize user input\n    user_vector = vectorizer.transform([query])\n    # Calculate cosine similarity\n    cosine_similarities = cosine_similarity(user_vector, tfidf_matrix).flatten()\n\n    # Rank and retrieve top-n recipes\n    top_n_indices = cosine_similarities.argsort()[::-1][:6]  # Assuming you want top 6 recipes\n    retrieved_result = [documents[i] for i in top_n_indices]\n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores, 5))\n\n# Compute the Mean Reciprocal Rank\nmap_score = np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\n\n# Print the scores\nprint(f\"MAP Score: {map_score}\")\nprint(f\"NDCG Score: {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-07T21:26:14.028037Z","iopub.execute_input":"2023-12-07T21:26:14.028395Z","iopub.status.idle":"2023-12-07T21:26:14.573102Z","shell.execute_reply.started":"2023-12-07T21:26:14.028367Z","shell.execute_reply":"2023-12-07T21:26:14.571827Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stdout","text":"MAP Score: 0.3758064516129032\nNDCG Score: 0.42406499474548676\nMean Reciprocal Rank Score: 0.37741935483870964\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## FAISS","metadata":{}},{"cell_type":"code","source":"! pip install numpy","metadata":{"execution":{"iopub.status.busy":"2023-12-07T21:34:43.105708Z","iopub.execute_input":"2023-12-07T21:34:43.106104Z","iopub.status.idle":"2023-12-07T21:34:53.012194Z","shell.execute_reply.started":"2023-12-07T21:34:43.106078Z","shell.execute_reply":"2023-12-07T21:34:53.010804Z"},"trusted":true},"execution_count":163,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade dill==0.3.2\n!pip install --upgrade pyarrow==3.0.0\n!pip install --upgrade packaging==23.0\n!pip install --upgrade overrides==6.0.1\n!pip install --upgrade jupyter-lsp==2.0.0\n!pip install --upgrade google-cloud-storage==2.2.1\n!pip install --upgrade kubernetes==8.0.0\n!pip install --upgrade opentelemetry-exporter-otlp-proto-grpc==1.19.0\n!pip install --upgrade opentelemetry-exporter-otlp-proto-common==1.19.0\n!pip install --upgrade opentelemetry-proto==1.19.0\n!pip install --upgrade opentelemetry-sdk~=1.19.0\n!pip install --upgrade packaging~=23.1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip -q install langchain huggingface_hub google-search-results tiktoken chromadb rank_bm25 faiss-cpu\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T01:51:19.565180Z","iopub.execute_input":"2023-12-08T01:51:19.565600Z","iopub.status.idle":"2023-12-08T01:52:14.027654Z","shell.execute_reply.started":"2023-12-08T01:51:19.565564Z","shell.execute_reply":"2023-12-08T01:52:14.026736Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\ngoogle-cloud-pubsublite 1.8.3 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.4.0 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.0.1 requires kubernetes<27,>=8.0.0, but you have kubernetes 28.1.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nopentelemetry-exporter-otlp 1.19.0 requires opentelemetry-exporter-otlp-proto-grpc==1.19.0, but you have opentelemetry-exporter-otlp-proto-grpc 1.21.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.19.0 requires opentelemetry-exporter-otlp-proto-common==1.19.0, but you have opentelemetry-exporter-otlp-proto-common 1.21.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.19.0 requires opentelemetry-proto==1.19.0, but you have opentelemetry-proto 1.21.0 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.19.0 requires opentelemetry-sdk~=1.19.0, but you have opentelemetry-sdk 1.21.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.retrievers import BM25Retriever, EnsembleRetriever\nfrom langchain.schema import Document\n\nfrom langchain.vectorstores import Chroma\nfrom langchain.vectorstores import FAISS\n\nfrom gensim.models import Word2Vec","metadata":{"execution":{"iopub.status.busy":"2023-12-08T01:52:26.727891Z","iopub.execute_input":"2023-12-08T01:52:26.728654Z","iopub.status.idle":"2023-12-08T01:52:38.179279Z","shell.execute_reply.started":"2023-12-08T01:52:26.728618Z","shell.execute_reply":"2023-12-08T01:52:38.178179Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df['Instructions'] = df['Instructions'].str.replace('\\n', ' ')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T01:53:00.961650Z","iopub.execute_input":"2023-12-08T01:53:00.962031Z","iopub.status.idle":"2023-12-08T01:53:00.999139Z","shell.execute_reply.started":"2023-12-08T01:53:00.962003Z","shell.execute_reply":"2023-12-08T01:53:00.998114Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import glob,json\n\n#Your desired template format\ntemplate = \"Recipe id is {}. Recipe name is {}. Ingredients are {}. Instructions are {}\"\n\n# List to store the formatted strings\ndocs = []\n\n# Iterate through each row in the DataFrame\nfor index, row in df.iterrows():\n    # Extract values from each column\n    recipe_id = row['Unnamed: 0.1']\n    recipe_name = row['Title']\n    ingredients = row['processed_ingredients']\n    instructions = row['Instructions']\n\n    # Create a formatted string using the template\n    formatted_string = template.format(recipe_id, recipe_name, ingredients, instructions)\n    formatted_dict = {\n        'content': formatted_string,\n        'id': recipe_id\n    }\n\n    # Convert the dictionary to a JSON string\n    doc = formatted_string\n    docs.append(formatted_string)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T02:03:56.129464Z","iopub.execute_input":"2023-12-08T02:03:56.129859Z","iopub.status.idle":"2023-12-08T02:03:57.150145Z","shell.execute_reply.started":"2023-12-08T02:03:56.129829Z","shell.execute_reply":"2023-12-08T02:03:57.149147Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-12-08T01:57:14.619587Z","iopub.execute_input":"2023-12-08T01:57:14.620165Z","iopub.status.idle":"2023-12-08T01:57:26.691630Z","shell.execute_reply.started":"2023-12-08T01:57:14.620124Z","shell.execute_reply":"2023-12-08T01:57:26.690167Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.35.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install faiss-cpu\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T01:57:26.693677Z","iopub.execute_input":"2023-12-08T01:57:26.694059Z","iopub.status.idle":"2023-12-08T01:57:38.347591Z","shell.execute_reply.started":"2023-12-08T01:57:26.694014Z","shell.execute_reply":"2023-12-08T01:57:38.346327Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.7.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.embeddings import SentenceTransformerEmbeddings \n\nembeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")","metadata":{"execution":{"iopub.status.busy":"2023-12-08T01:57:52.977011Z","iopub.execute_input":"2023-12-08T01:57:52.977474Z","iopub.status.idle":"2023-12-08T01:58:08.366690Z","shell.execute_reply.started":"2023-12-08T01:57:52.977439Z","shell.execute_reply":"2023-12-08T01:58:08.365615Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c6bcecd10f474b849b1b636b6cc728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af8b59095b0e453a9b088e4113a4efcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8ef3259ecb444d984399cc29a24b104"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e19d93631e64f7d89018ab72b32099d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9195c5a3efc14b8a995a94aad8b5d552"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5189959e6f4545f78000c09de2f7f828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f95811661414b479f0599bbba4a2615"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6be20df3c3df4b4e80959cf2f9d9212e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a75ed666c20d48b397df04cb869a292f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b24e52d5080490fa25e414b9e1011a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a2c93e6ba74a19ad755a6c65070992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e000b701bf9749fd9187e486b86ba30f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acf88d5129844c2a880d57c670ba3f62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9437643a0be9460185951573fdcd464a"}},"metadata":{}}]},{"cell_type":"code","source":"faiss_vectorstore = FAISS.from_texts(docs, embeddings)\nfaiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 4})","metadata":{"execution":{"iopub.status.busy":"2023-12-08T02:38:26.117648Z","iopub.execute_input":"2023-12-08T02:38:26.118119Z","iopub.status.idle":"2023-12-08T02:56:11.589259Z","shell.execute_reply.started":"2023-12-08T02:38:26.118079Z","shell.execute_reply":"2023-12-08T02:56:11.588068Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c001f829b04566b8598aed6318eb48"}},"metadata":{}}]},{"cell_type":"code","source":"s = faiss_retriever.get_relevant_documents(\"egg whites, new potatoes, kosher salt, finely ground black pepper, rosemary, thyme, parsley\")","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:21:16.793574Z","iopub.execute_input":"2023-12-08T03:21:16.793996Z","iopub.status.idle":"2023-12-08T03:21:16.839292Z","shell.execute_reply.started":"2023-12-08T03:21:16.793962Z","shell.execute_reply":"2023-12-08T03:21:16.838079Z"},"trusted":true},"execution_count":76,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb5c8e03dc284892876a0a9ad4f8ba54"}},"metadata":{}}]},{"cell_type":"code","source":"s","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:21:19.311549Z","iopub.execute_input":"2023-12-08T03:21:19.312739Z","iopub.status.idle":"2023-12-08T03:21:19.320755Z","shell.execute_reply.started":"2023-12-08T03:21:19.312687Z","shell.execute_reply":"2023-12-08T03:21:19.319752Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='Recipe id is 6360. Recipe name is Buttermilk Green Goddess Dressing. Ingredients are mayonnaise buttermilk fresh chive flat leaf parsley fresh tarragon fresh lemon juice anchovy fillet packed oil garlic kosher salt freshly ground black pepper. Instructions are In a processor, purée 1/2 cup mayonnaise, 1/3 cup buttermilk, 1/4 cup chopped fresh chives, 1/4 cup coarsely chopped flat-leaf parsley, 1 tablespoon chopped fresh tarragon, 1 tablespoon fresh lemon juice, 2 anchovy fillets packed in oil (drained, chopped), and 1 chopped garlic clove until smooth. Season with kosher salt and freshly ground black pepper. DO AHEAD: Can be made 2 hours ahead. Cover and chill.'),\n Document(page_content='Recipe id is 1. Recipe name is Crispy Salt and Pepper Potatoes. Ingredients are egg white new potato kosher salt finely ground black pepper rosemary thyme parsley. Instructions are Preheat oven to 400°F and line a rimmed baking sheet with parchment. In a large bowl, whisk the egg whites until foamy (there shouldn’t be any liquid whites in the bowl). Add the potatoes and toss until they’re well coated with the egg whites, then transfer to a strainer or colander and let the excess whites drain. Season the potatoes with the salt, pepper, and herbs. Scatter the potatoes on the baking sheet (make sure they’re not touching) and roast until the potatoes are very crispy and tender when poked with a knife, 15 to 20 minutes (depending on the size of the potatoes). Transfer to a bowl and serve.'),\n Document(page_content='Recipe id is 5614. Recipe name is Smoked Salmon Smørrebrød. Ingredients are mashed potato sour cream fresh horseradish fresh dill fresh flat leaf parsley fresh lemon juice kosher salt ground pepper danish rye pumpernickel bread smoked salmon radish salmon trout roe dill sprig flat leaf parsley leaf kosher salt ground pepper. Instructions are Whisk potatoes, if using, sour cream, horseradish, dill, parsley, and lemon juice in a small bowl; season with salt and pepper. Spread horseradish sour cream on bread and top with smoked salmon, radishes, roe, if using, dill, and parsley. Season with pepper.'),\n Document(page_content='Recipe id is 11894. Recipe name is Winter Salad. Ingredients are shallot honey fresh orange juice sherry vinegar salt white pepper extra virgin olive oil belgian endive red onion fennel celery root granny smith apple mizuna mustard green firm aged goat cheese white truffle oil. Instructions are Whisk together shallot, honey, orange juice, vinegar, salt, and white pepper in a bowl, then add olive oil in a stream, whisking until combined. Toss endives, onion, fennel, celery root, apple, and mizuna with 1/2 cup dressing in a large bowl. Season with salt and white pepper. Serve salad topped with cheese and drizzled with truffle oil. *Available at specialty foods shops and many supermarkets. **Available at specialty foods shops and Dean & DeLuca (800-221-7714).')]"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport re\n\ndef retrieve_and_filter_df(df, s):\n    \"\"\"\n    Retrieves and filters a DataFrame based on a list of items with 'page_content' attribute.\n\n    Parameters:\n    - df (pd.DataFrame): The original DataFrame.\n    - s (list): A list of items where each item is an object with a 'page_content' attribute.\n\n    Returns:\n    - pd.DataFrame: The filtered DataFrame.\n    \"\"\"\n\n    # Initialize an empty DataFrame to store the results\n    rst = pd.DataFrame(columns=df.columns)\n    retrieved_docs = []\n\n    for idx, item in enumerate(s):\n        # Extract the numeric ID from the 'page_content' attribute\n        match = re.search(r'\\b(\\d+)\\b', item.page_content)\n        if match:\n            value_to_find = int(match.group(1))\n\n            # Use the value to filter rows in the DataFrame\n            mask = df['Unnamed: 0.1'] == value_to_find\n            rows_with_value = df[mask]\n            rst = pd.concat([rst, rows_with_value])\n            retrieved_docs.append(rst)\n\n    return rst\n\n# Example usage:\n# Call the function with your DataFrame 'df' and the list 's'\n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:21:27.546516Z","iopub.execute_input":"2023-12-08T03:21:27.546938Z","iopub.status.idle":"2023-12-08T03:21:27.568005Z","shell.execute_reply.started":"2023-12-08T03:21:27.546904Z","shell.execute_reply":"2023-12-08T03:21:27.566871Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"      Unnamed: 0 Unnamed: 0.1                              Title  \\\n6360        6360         6360  Buttermilk Green Goddess Dressing   \n1              1            1    Crispy Salt and Pepper Potatoes   \n5614        5614         5614           Smoked Salmon Smørrebrød   \n11894      11894        11894                       Winter Salad   \n\n                                             Ingredients  \\\n6360   ['1/2 cup mayonnaise', '1/3 cup buttermilk', '...   \n1      ['2 large egg whites', '1 pound new potatoes (...   \n5614   ['1/2 cup mashed potatoes (optional)', '1/2 cu...   \n11894  ['2 teaspoons finely chopped shallot', '1 teas...   \n\n                                            Instructions  \\\n6360   In a processor, purée 1/2 cup mayonnaise, 1/3 ...   \n1      Preheat oven to 400°F and line a rimmed baking...   \n5614   Whisk potatoes, if using, sour cream, horserad...   \n11894  Whisk together shallot, honey, orange juice, v...   \n\n                                     Cleaned_Ingredients  \\\n6360   ['1/2 cup mayonnaise', '1/3 cup buttermilk', '...   \n1      ['2 large egg whites', '1 pound new potatoes (...   \n5614   ['1/2 cup mashed potatoes (optional)', '1/2 cu...   \n11894  ['2 teaspoons finely chopped shallot', '1 teas...   \n\n                                               final_ing  \\\n6360   ['mayonnaise', 'buttermilk', 'fresh chives', '...   \n1      ['egg whites', 'new potatoes', 'kosher salt', ...   \n5614   ['mashed potatoes', 'sour cream', 'fresh horse...   \n11894  ['shallot', 'honey', 'fresh orange juice', 'sh...   \n\n                                   processed_ingredients  \n6360   mayonnaise buttermilk fresh chive flat leaf pa...  \n1      egg white new potato kosher salt finely ground...  \n5614   mashed potato sour cream fresh horseradish fre...  \n11894  shallot honey fresh orange juice sherry vinega...  \n","output_type":"stream"}]},{"cell_type":"code","source":"result_df = retrieve_and_filter_df(df, s)\nresult_df","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:21:32.621769Z","iopub.execute_input":"2023-12-08T03:21:32.622276Z","iopub.status.idle":"2023-12-08T03:21:32.648726Z","shell.execute_reply.started":"2023-12-08T03:21:32.622235Z","shell.execute_reply":"2023-12-08T03:21:32.647571Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"      Unnamed: 0 Unnamed: 0.1                              Title  \\\n6360        6360         6360  Buttermilk Green Goddess Dressing   \n1              1            1    Crispy Salt and Pepper Potatoes   \n5614        5614         5614           Smoked Salmon Smørrebrød   \n11894      11894        11894                       Winter Salad   \n\n                                             Ingredients  \\\n6360   ['1/2 cup mayonnaise', '1/3 cup buttermilk', '...   \n1      ['2 large egg whites', '1 pound new potatoes (...   \n5614   ['1/2 cup mashed potatoes (optional)', '1/2 cu...   \n11894  ['2 teaspoons finely chopped shallot', '1 teas...   \n\n                                            Instructions  \\\n6360   In a processor, purée 1/2 cup mayonnaise, 1/3 ...   \n1      Preheat oven to 400°F and line a rimmed baking...   \n5614   Whisk potatoes, if using, sour cream, horserad...   \n11894  Whisk together shallot, honey, orange juice, v...   \n\n                                     Cleaned_Ingredients  \\\n6360   ['1/2 cup mayonnaise', '1/3 cup buttermilk', '...   \n1      ['2 large egg whites', '1 pound new potatoes (...   \n5614   ['1/2 cup mashed potatoes (optional)', '1/2 cu...   \n11894  ['2 teaspoons finely chopped shallot', '1 teas...   \n\n                                               final_ing  \\\n6360   ['mayonnaise', 'buttermilk', 'fresh chives', '...   \n1      ['egg whites', 'new potatoes', 'kosher salt', ...   \n5614   ['mashed potatoes', 'sour cream', 'fresh horse...   \n11894  ['shallot', 'honey', 'fresh orange juice', 'sh...   \n\n                                   processed_ingredients  \n6360   mayonnaise buttermilk fresh chive flat leaf pa...  \n1      egg white new potato kosher salt finely ground...  \n5614   mashed potato sour cream fresh horseradish fre...  \n11894  shallot honey fresh orange juice sherry vinega...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>Title</th>\n      <th>Ingredients</th>\n      <th>Instructions</th>\n      <th>Cleaned_Ingredients</th>\n      <th>final_ing</th>\n      <th>processed_ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6360</th>\n      <td>6360</td>\n      <td>6360</td>\n      <td>Buttermilk Green Goddess Dressing</td>\n      <td>['1/2 cup mayonnaise', '1/3 cup buttermilk', '...</td>\n      <td>In a processor, purée 1/2 cup mayonnaise, 1/3 ...</td>\n      <td>['1/2 cup mayonnaise', '1/3 cup buttermilk', '...</td>\n      <td>['mayonnaise', 'buttermilk', 'fresh chives', '...</td>\n      <td>mayonnaise buttermilk fresh chive flat leaf pa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Crispy Salt and Pepper Potatoes</td>\n      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n      <td>Preheat oven to 400°F and line a rimmed baking...</td>\n      <td>['2 large egg whites', '1 pound new potatoes (...</td>\n      <td>['egg whites', 'new potatoes', 'kosher salt', ...</td>\n      <td>egg white new potato kosher salt finely ground...</td>\n    </tr>\n    <tr>\n      <th>5614</th>\n      <td>5614</td>\n      <td>5614</td>\n      <td>Smoked Salmon Smørrebrød</td>\n      <td>['1/2 cup mashed potatoes (optional)', '1/2 cu...</td>\n      <td>Whisk potatoes, if using, sour cream, horserad...</td>\n      <td>['1/2 cup mashed potatoes (optional)', '1/2 cu...</td>\n      <td>['mashed potatoes', 'sour cream', 'fresh horse...</td>\n      <td>mashed potato sour cream fresh horseradish fre...</td>\n    </tr>\n    <tr>\n      <th>11894</th>\n      <td>11894</td>\n      <td>11894</td>\n      <td>Winter Salad</td>\n      <td>['2 teaspoons finely chopped shallot', '1 teas...</td>\n      <td>Whisk together shallot, honey, orange juice, v...</td>\n      <td>['2 teaspoons finely chopped shallot', '1 teas...</td>\n      <td>['shallot', 'honey', 'fresh orange juice', 'sh...</td>\n      <td>shallot honey fresh orange juice sherry vinega...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport ast\nfrom ast import literal_eval\nimport random\nimport numpy as np\n\n# Add your definition of average_precision, ndcg_at_k, and preprocess functions here\n\ndf_test = pd.read_excel(\"/kaggle/input/validation/validation_set.xlsx\")\n\naverage_precisions = []\navg_ndcg = []\nrelevance_score_list = []\n\nfor index, row in df_test.iterrows():\n    expected_result = []\n    query = literal_eval(row['Test_Query'])\n    query =  \", \".join(query)\n\n    expected_id = literal_eval(row['Recipe_IDs'])\n    expected_result += [df.iloc[idx]['processed_ingredients'] for idx in expected_id]\n\n    # Use faiss_retriever to get relevant documents\n    s = faiss_retriever.get_relevant_documents(query)\n    retriver_df =retrieve_and_filter_df(df, s)\n\n    # Assuming 's' is a list of items where each item is an object with a 'page_content' attribute\n    retrieved_result = [item for item in retriver_df['processed_ingredients']]\n    \n    \n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores, 5))\n\n# Compute the Mean Reciprocal Rank\nmap_score = np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\n\n# Print the scores\nprint(f\"MAP Score: {map_score}\")\nprint(f\"NDCG Score: {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:24:53.752780Z","iopub.execute_input":"2023-12-08T03:24:53.753201Z","iopub.status.idle":"2023-12-08T03:24:55.491833Z","shell.execute_reply.started":"2023-12-08T03:24:53.753169Z","shell.execute_reply":"2023-12-08T03:24:55.491075Z"},"trusted":true},"execution_count":85,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d9759eb558941368e51e49bf270e850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e1494f40f74ec4a0b9a2194d1fdce7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d2fe8b5ba9a4a869a8aa4a50cbef72b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ea3c898a374bc4b9972b8fc198a8c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77bbe782f4dd478389e2e613b89026e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f3620b2fb034bc092b06287768d9917"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15eb903c606645418dc15e649c97ac53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23133344b67e454aad5fcef590529d5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a85e38e7e7914310b6ebcd920efbbf4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a39b8886bfb4349a7039c3dc680172b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2526089dbdef4c9ca23dd22cd69ef1d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dc29cbb2df648d1bc60c005b72b56b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e21bd5778541dd870f2910e03a9c58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b65c9dc8d3e474cbacdcf736851b10b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e240f58181e4cf4af4cdc4daee96576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af6d160711134c21a3c0db73060f7c77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e56f9ba71e6f4fa6a10cc32053ddc66b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87dbb9e7e3f54b62a03bce9f5fd9222a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738238bb94764afab4eed83e3c7b3a2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"554a1c2bbe4948998a01a416a4930f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"701dc25ce87d41b78cd4ce913b60473d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0326a5d89e0a4c44a601f39dc292c4c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36fbbb3dc31b48f7bb232063b906f1cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a8b35fe3e7f47d7bafec3a892eeaf44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe6b244657c249e3a05a3fc4ae8c4796"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7faebc7a62534aa683fd7921e7a8abda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64ed851be15d4658b76ac233a986912d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1294fb1824d84b6daee983b79e253b70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95d1f71cf17a4eb4aed3e4fd8df72fd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8e69ac7498e4fa58e68798170fb8902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f720c5ca6616461c897d9f2685ae162e"}},"metadata":{}},{"name":"stdout","text":"MAP Score: 0.5698924731182795\nNDCG Score: 0.6273030525921673\nMean Reciprocal Rank Score: 0.5752688172043011\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## ENSEMBLE RETRIVER ","metadata":{}},{"cell_type":"code","source":"# initialize the bm25 retriever and faiss retriever\nbm25_retriever = BM25Retriever.from_texts(pt)\nbm25_retriever.k = 5","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:31:45.600434Z","iopub.execute_input":"2023-12-08T03:31:45.600860Z","iopub.status.idle":"2023-12-08T03:31:46.000951Z","shell.execute_reply.started":"2023-12-08T03:31:45.600830Z","shell.execute_reply":"2023-12-08T03:31:45.999687Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"bm25_retriever.get_relevant_documents(\"Generapte recipe using whole chicken, kosher salt, acorn squash, sage\")","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:28:03.419585Z","iopub.execute_input":"2023-12-08T03:28:03.420014Z","iopub.status.idle":"2023-12-08T03:28:03.572792Z","shell.execute_reply.started":"2023-12-08T03:28:03.419977Z","shell.execute_reply":"2023-12-08T03:28:03.571585Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='delicata acorn squash garlic sage thyme extra virgin olive oil kosher salt white wine vinegar'),\n Document(page_content='acorn squash extra virgin olive oil fresh nutmeg honey sage leaf salt freshly ground black pepper'),\n Document(page_content='fresh hatch chile unsalted butter onion garlic using microplane kosher salt purpose flour ground cumin whole milk cheddar cheese monterey jack cheese plum tomato cilantro white corn tortilla chip'),\n Document(page_content='buttery sugar cookie dough recipe dulce de leche cream cheese sugar egg pure vanilla extract'),\n Document(page_content='using electric mixer powdered sugar egg white minute add lemon juice divide icing add different food coloring')]"},"metadata":{}}]},{"cell_type":"code","source":"# initialize the ensemble retriever\nensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever],\n                                       weights=[0.4, 0.8])","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:28:10.738724Z","iopub.execute_input":"2023-12-08T03:28:10.739154Z","iopub.status.idle":"2023-12-08T03:28:10.744304Z","shell.execute_reply.started":"2023-12-08T03:28:10.739119Z","shell.execute_reply":"2023-12-08T03:28:10.743071Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"dc = ensemble_retriever.get_relevant_documents(\"whole chicken, kosher salt, acorn squash sage\")","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:28:14.747109Z","iopub.execute_input":"2023-12-08T03:28:14.747497Z","iopub.status.idle":"2023-12-08T03:28:15.022285Z","shell.execute_reply.started":"2023-12-08T03:28:14.747468Z","shell.execute_reply":"2023-12-08T03:28:15.021438Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6dfa1580e944fd0aab75e8819de1bb2"}},"metadata":{}}]},{"cell_type":"code","source":"dc","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:47:41.566775Z","iopub.execute_input":"2023-12-08T03:47:41.567198Z","iopub.status.idle":"2023-12-08T03:47:41.574888Z","shell.execute_reply.started":"2023-12-08T03:47:41.567166Z","shell.execute_reply":"2023-12-08T03:47:41.574141Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='Recipe id is 0. Recipe name is Miso-Butter Roast Chicken With Acorn Squash Panzanella. Ingredients are whole chicken kosher salt acorn squash sage rosemary unsalted butter ground allspice crushed red pepper flake freshly ground black pepper white bread apple extra virgin olive oil red onion apple cider vinegar white miso purpose flour unsalted butter dry white wine unsalted chicken broth white miso kosher salt freshly ground pepper. Instructions are Pat chicken dry with paper towels, season all over with 2 tsp. salt, and tie legs together with kitchen twine. Let sit at room temperature 1 hour. Meanwhile, halve squash and scoop out seeds. Run a vegetable peeler along ridges of squash halves to remove skin. Cut each half into ½\"-thick wedges; arrange on a rimmed baking sheet. Combine sage, rosemary, and 6 Tbsp. melted butter in a large bowl; pour half of mixture over squash on baking sheet. Sprinkle squash with allspice, red pepper flakes, and ½ tsp. salt and season with black pepper; toss to coat. Add bread, apples, oil, and ¼ tsp. salt to remaining herb butter in bowl; season with black pepper and toss to combine. Set aside. Place onion and vinegar in a small bowl; season with salt and toss to coat. Let sit, tossing occasionally, until ready to serve. Place a rack in middle and lower third of oven; preheat to 425°F. Mix miso and 3 Tbsp. room-temperature butter in a small bowl until smooth. Pat chicken dry with paper towels, then rub or brush all over with miso butter. Place chicken in a large cast-iron skillet and roast on middle rack until an instant-read thermometer inserted into the thickest part of breast registers 155°F, 50–60 minutes. (Temperature will climb to 165°F while chicken rests.) Let chicken rest in skillet at least 5 minutes, then transfer to a plate; reserve skillet. Meanwhile, roast squash on lower rack until mostly tender, about 25 minutes. Remove from oven and scatter reserved bread mixture over, spreading into as even a layer as you can manage. Return to oven and roast until bread is golden brown and crisp and apples are tender, about 15 minutes. Remove from oven, drain pickled onions, and toss to combine. Transfer to a serving dish. Using your fingers, mash flour and butter in a small bowl to combine. Set reserved skillet with chicken drippings over medium heat. You should have about ¼ cup, but a little over or under is all good. (If you have significantly more, drain off and set excess aside.) Add wine and cook, stirring often and scraping up any browned bits with a wooden spoon, until bits are loosened and wine is reduced by about half (you should be able to smell the wine), about 2 minutes. Add butter mixture; cook, stirring often, until a smooth paste forms, about 2 minutes. Add broth and any reserved drippings and cook, stirring constantly, until combined and thickened, 6–8 minutes. Remove from heat and stir in miso. Taste and season with salt and black pepper. Serve chicken with gravy and squash panzanella alongside.'),\n Document(page_content='Recipe id is 10178. Recipe name is Butternut Squash and Sage Soup with Sage Breadcrumbs. Ingredients are butter olive oil onion fresh italian parsley fresh sage butternut squash coarse sea salt garlic chicken stock chicken broth fresh whole grain wheat bread butter fresh sage. Instructions are Melt butter with oil in large pot over medium-high heat. Add onions, parsley, and sage; sauté until onions are softened, about 5 minutes. Add squash and coarse salt; sauté until squash softens and onions are golden, about 6 minutes. Add garlic; stir 1 minute. Add 5 cups stock; bring to boil. Reduce heat, cover, and simmer until squash is very soft, about 25 minutes. Cool slightly. Working in batches, puree soup in blender, allowing some texture to remain. Return soup to pot. Thin with stock, if desired. Season with pepper and more salt, if desired. DO AHEAD: Can be made 1 day ahead. Chill uncovered until cold, then cover and chill. Rewarm before serving. Place bread in processor; blend until fine crumbs form but some slightly coarser crumbs remain. Cook butter in large nonstick skillet over medium heat until golden, about 2 minutes. Add breadcrumbs and sage. Cook until crumbs are crisp, stirring frequently, about 10 minutes. Remove from heat and cool. DO AHEAD: Can be made 4 hours ahead. Let stand uncovered at room temperature. Ladle soup into bowls. Sprinkle with breadcrumbs.'),\n Document(page_content=\"Recipe id is 5320. Recipe name is Roasted Poultry, Wild Boar Bacon, and Mushroom Farro with Pan-Roasted Fennel and Carrots. Ingredients are whole game hen chicken water carrot onion celery fresh rosemary fresh sage whole black peppercorn whole game hen chicken kosher salt freshly ground black pepper canola oil wild boar regular bacon shallot farro mushroom kosher salt freshly ground black pepper extra virgin olive oil fresh sage leaf whole green peppercorn blackberry dried currant dry red wine honey red wine vinegar fennel carrot olive oil kosher salt freshly ground black pepper maple syrup vinegar equipment. Instructions are In a large stockpot, combine the bones, water, carrots, onion, celery, rosemary, sage, and peppercorns and bring to a boil. Reduce the heat and simmer for about 3 hours, skimming occasionally. Strain the stock. Measure 3 1/2 cups of stock for cooking the farro, and reserve any leftovers for later use. Preheat the oven to 350°F. Cut each of the game hens, chickens, or pigeons in half then season all over with kosher salt and freshly ground black pepper. In a large sauté pan over moderately high heat, warm the oil. Working in batches, add the birds, skin side down, to the pan and sear until the skin is golden brown and caramelized. Transfer the birds, as done, to a roasting pan or large rimmed baking sheet and roast in the oven until an instant-read thermometer inserted into the thickest part of the thigh (do not touch the bone) registers 165°F. In a medium saucepan over moderate heat, cook the bacon until crispy. Transfer the bacon to a paper towel–lined plate and pour half the rendered bacon fat into a medium sauté pan and set aside. Add the shallot to the original saucepan and sauté, stirring occasionally, until translucent then add the farro and sauté, stirring occasionally, until just toasted. Add the reserved 3 1/2 cups of stock to the farro and bring to a simmer. Continue simmering until soft and tender. While the farro is simmering, heat the rendered bacon fat in the medium sauté pan. Add the mushrooms and sauté, stirring occasionally, until the liquid released by the mushrooms is evaporated, about 5 minutes. Season with kosher salt and freshly ground black pepper. Add the mushrooms and bacon to the farro and stir to combine. Keep warm. In a small saucepan over moderately low heat, bring the olive oil, sage, and peppercorns to a simmer. Shut off the heat and let the oil cool until it's fragrant with sage and peppercorn. Once cool, strain the oil. In small saucepan over moderate heat, bring the blackberries, currants, red wine, honey, and vinegar to a simmer. Continue simmering until the mixture is thick and jamlike, 8 to 12 minutes. Remove from the heat and set aside. Preheat the oven to 450°F. Arrange the fennel and carrots in separate baking dishes or baking sheets. Drizzle each with 1 tablespoon olive oil then season with kosher salt and freshly ground black pepper. Roast, turning occasionally, until tender and well caramelized, about 15 minutes. Transfer to a large bowl, drizzle with the maple syrup and vinegar, season with kosher salt and freshly ground black pepper, if desired, and toss to combine. Divide the farro among 4 plates, then top each with vegetables and poultry. Garnish the plates with the berry compote and sage oil.\"),\n Document(page_content='Recipe id is 1022. Recipe name is Slow-Cooked Winter Squash with Sage and Thyme. Ingredients are delicata acorn squash garlic sage thyme extra virgin olive oil kosher salt white wine vinegar. Instructions are Place a rack in middle of oven and preheat to 350°F. Toss squash, garlic, sage, thyme, oil, and salt in a shallow 2-qt. baking dish to combine. Turn garlic cut side down, then roast vegetables, tossing 2 or 3 times, until golden brown, very tender, and edges and cut sides are crisp, 60–70 minutes. Let cool slightly, then add vinegar and toss to coat.'),\n Document(page_content='delicata acorn squash garlic sage thyme extra virgin olive oil kosher salt white wine vinegar'),\n Document(page_content='acorn squash extra virgin olive oil fresh nutmeg honey sage leaf salt freshly ground black pepper'),\n Document(page_content='extra virgin olive oil acorn squash salt black pepper whole chestnut pancetta fresh cranberry dark brown sugar water whole grain mustard chicory'),\n Document(page_content='pomegranate juice balsamic vinegar red wine vinegar extra virgin olive oil butter delicata squash acorn squash dandelion green pomegranate seed pine nut'),\n Document(page_content='scallion garlic seasoned rice vinegar sesame oil soy sauce honey ginger kabocha acorn squash sesame seed')]"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport re\n\ndef retrieve_and_filter_df_en(df, s):\n    \"\"\"\n    Retrieves and filters a DataFrame based on a list of items with 'page_content' attribute.\n\n    Parameters:\n    - df (pd.DataFrame): The original DataFrame.\n    - s (list): A list of items where each item is an object with a 'page_content' attribute.\n\n    Returns:\n    - pd.DataFrame: The filtered DataFrame.\n    \"\"\"\n\n    # Initialize an empty DataFrame to store the results\n    rst = pd.DataFrame(columns=df.columns)\n    retrieved_docs = []\n\n    for idx, item in enumerate(s):\n        # Extract the numeric ID from the 'page_content' attribute\n        item = item.page_content\n        if item[0:6]==\"Recipe\":\n            match = re.search(r'\\b(\\d+)\\b', item)\n            if match:\n                value_to_find = int(match.group(1))\n\n                # Use the value to filter rows in the DataFrame\n                mask = df['Unnamed: 0.1'] == value_to_find\n                rows_with_value = df[mask]\n                rst = pd.concat([rst, rows_with_value])\n                retrieved_docs.append(rst)\n        else: \n            for index, row in df.iterrows():\n        # Check if the match_string is present in any column of the current row\n                if any(item.lower() in str(value).lower() for value in row):\n                    rst = pd.concat([rst, pd.DataFrame(row).transpose()], ignore_index=True)\n\n            \n\n    return rst\nretrieve_and_filter_df_en(df,dc)","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:51:08.851009Z","iopub.execute_input":"2023-12-08T03:51:08.851407Z","iopub.status.idle":"2023-12-08T03:51:14.301470Z","shell.execute_reply.started":"2023-12-08T03:51:08.851377Z","shell.execute_reply":"2023-12-08T03:51:14.300319Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"  Unnamed: 0 Unnamed: 0.1                                              Title  \\\n0          0            0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n1      10178        10178  Butternut Squash and Sage Soup with Sage Bread...   \n2       5320         5320  Roasted Poultry, Wild Boar Bacon, and Mushroom...   \n3       1022         1022      Slow-Cooked Winter Squash with Sage and Thyme   \n4       1022         1022      Slow-Cooked Winter Squash with Sage and Thyme   \n5       1469         1469                     Roasted Acorn Squash and Honey   \n6      12974        12974  Roasted Squash, Chestnut, and Chicory Salad wi...   \n7      12219        12219  Dandelion Salad with Pomegranate Seeds, Pine N...   \n8        342          342           Steamed Kabocha With Ginger-Soy Dressing   \n\n                                         Ingredients  \\\n0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n1  ['1 1/2 tablespoons butter', '1 1/2 tablespoon...   \n2  ['Bones from 4 whole game hens, small chickens...   \n3  ['1 lb. delicata or acorn squash, halved lengt...   \n4  ['1 lb. delicata or acorn squash, halved lengt...   \n5  ['2 acorn squash (about 1 pound each)', '2 tab...   \n6  ['2 tablespoons extra-virgin olive oil plus ad...   \n7  ['6 tablespoons pomegranate juice', '1 1/2 tab...   \n8  ['3 scallions, white and dark green parts sepa...   \n\n                                        Instructions  \\\n0  Pat chicken dry with paper towels, season all ...   \n1  Melt butter with oil in large pot over medium-...   \n2  In a large stockpot, combine the bones, water,...   \n3  Place a rack in middle of oven and preheat to ...   \n4  Place a rack in middle of oven and preheat to ...   \n5  Preheat the oven to 350°F. Split the squash in...   \n6  Put oven rack in middle position and preheat o...   \n7  Whisk pomegranate juice and vinegars in bowl. ...   \n8  Pour water into a large saucepan, wide skillet...   \n\n                                 Cleaned_Ingredients  \\\n0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...   \n1  ['1 1/2 tablespoons butter', '1 1/2 tablespoon...   \n2  ['Bones from 4 whole game hens, small chickens...   \n3  ['1 lb. delicata or acorn squash, halved lengt...   \n4  ['1 lb. delicata or acorn squash, halved lengt...   \n5  ['2 acorn squash (about 1 pound each)', '2 tab...   \n6  ['2 tablespoons extra-virgin olive oil plus ad...   \n7  ['6 tablespoons pomegranate juice', '1 1/2 tab...   \n8  ['3 scallions, white and dark green parts sepa...   \n\n                                           final_ing  \\\n0  ['whole chicken', 'kosher salt', 'acorn squash...   \n1  ['butter', 'olive oil', 'onions', 'fresh itali...   \n2  ['whole game hens, chickens', 'water', 'carrot...   \n3  ['delicata or acorn squash', 'garlic', 'sage',...   \n4  ['delicata or acorn squash', 'garlic', 'sage',...   \n5  ['acorn squash', 'extra-virgin olive oil', 'fr...   \n6  ['extra-virgin olive oil', 'acorn squash', 'sa...   \n7  ['pomegranate juice', 'balsamic vinegar', 'red...   \n8  ['scallions', 'garlic', 'seasoned rice vinegar...   \n\n                               processed_ingredients  \n0  whole chicken kosher salt acorn squash sage ro...  \n1  butter olive oil onion fresh italian parsley f...  \n2  whole game hen chicken water carrot onion cele...  \n3  delicata acorn squash garlic sage thyme extra ...  \n4  delicata acorn squash garlic sage thyme extra ...  \n5  acorn squash extra virgin olive oil fresh nutm...  \n6  extra virgin olive oil acorn squash salt black...  \n7  pomegranate juice balsamic vinegar red wine vi...  \n8  scallion garlic seasoned rice vinegar sesame o...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>Title</th>\n      <th>Ingredients</th>\n      <th>Instructions</th>\n      <th>Cleaned_Ingredients</th>\n      <th>final_ing</th>\n      <th>processed_ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Miso-Butter Roast Chicken With Acorn Squash Pa...</td>\n      <td>['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...</td>\n      <td>Pat chicken dry with paper towels, season all ...</td>\n      <td>['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...</td>\n      <td>['whole chicken', 'kosher salt', 'acorn squash...</td>\n      <td>whole chicken kosher salt acorn squash sage ro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10178</td>\n      <td>10178</td>\n      <td>Butternut Squash and Sage Soup with Sage Bread...</td>\n      <td>['1 1/2 tablespoons butter', '1 1/2 tablespoon...</td>\n      <td>Melt butter with oil in large pot over medium-...</td>\n      <td>['1 1/2 tablespoons butter', '1 1/2 tablespoon...</td>\n      <td>['butter', 'olive oil', 'onions', 'fresh itali...</td>\n      <td>butter olive oil onion fresh italian parsley f...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5320</td>\n      <td>5320</td>\n      <td>Roasted Poultry, Wild Boar Bacon, and Mushroom...</td>\n      <td>['Bones from 4 whole game hens, small chickens...</td>\n      <td>In a large stockpot, combine the bones, water,...</td>\n      <td>['Bones from 4 whole game hens, small chickens...</td>\n      <td>['whole game hens, chickens', 'water', 'carrot...</td>\n      <td>whole game hen chicken water carrot onion cele...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1022</td>\n      <td>1022</td>\n      <td>Slow-Cooked Winter Squash with Sage and Thyme</td>\n      <td>['1 lb. delicata or acorn squash, halved lengt...</td>\n      <td>Place a rack in middle of oven and preheat to ...</td>\n      <td>['1 lb. delicata or acorn squash, halved lengt...</td>\n      <td>['delicata or acorn squash', 'garlic', 'sage',...</td>\n      <td>delicata acorn squash garlic sage thyme extra ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1022</td>\n      <td>1022</td>\n      <td>Slow-Cooked Winter Squash with Sage and Thyme</td>\n      <td>['1 lb. delicata or acorn squash, halved lengt...</td>\n      <td>Place a rack in middle of oven and preheat to ...</td>\n      <td>['1 lb. delicata or acorn squash, halved lengt...</td>\n      <td>['delicata or acorn squash', 'garlic', 'sage',...</td>\n      <td>delicata acorn squash garlic sage thyme extra ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1469</td>\n      <td>1469</td>\n      <td>Roasted Acorn Squash and Honey</td>\n      <td>['2 acorn squash (about 1 pound each)', '2 tab...</td>\n      <td>Preheat the oven to 350°F. Split the squash in...</td>\n      <td>['2 acorn squash (about 1 pound each)', '2 tab...</td>\n      <td>['acorn squash', 'extra-virgin olive oil', 'fr...</td>\n      <td>acorn squash extra virgin olive oil fresh nutm...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>12974</td>\n      <td>12974</td>\n      <td>Roasted Squash, Chestnut, and Chicory Salad wi...</td>\n      <td>['2 tablespoons extra-virgin olive oil plus ad...</td>\n      <td>Put oven rack in middle position and preheat o...</td>\n      <td>['2 tablespoons extra-virgin olive oil plus ad...</td>\n      <td>['extra-virgin olive oil', 'acorn squash', 'sa...</td>\n      <td>extra virgin olive oil acorn squash salt black...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>12219</td>\n      <td>12219</td>\n      <td>Dandelion Salad with Pomegranate Seeds, Pine N...</td>\n      <td>['6 tablespoons pomegranate juice', '1 1/2 tab...</td>\n      <td>Whisk pomegranate juice and vinegars in bowl. ...</td>\n      <td>['6 tablespoons pomegranate juice', '1 1/2 tab...</td>\n      <td>['pomegranate juice', 'balsamic vinegar', 'red...</td>\n      <td>pomegranate juice balsamic vinegar red wine vi...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>342</td>\n      <td>342</td>\n      <td>Steamed Kabocha With Ginger-Soy Dressing</td>\n      <td>['3 scallions, white and dark green parts sepa...</td>\n      <td>Pour water into a large saucepan, wide skillet...</td>\n      <td>['3 scallions, white and dark green parts sepa...</td>\n      <td>['scallions', 'garlic', 'seasoned rice vinegar...</td>\n      <td>scallion garlic seasoned rice vinegar sesame o...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport ast\nfrom ast import literal_eval\nimport random\nimport numpy as np\n\n# Add your definition of average_precision, ndcg_at_k, and preprocess functions here\n\ndf_test = pd.read_excel(\"/kaggle/input/validation/validation_set.xlsx\")\n\naverage_precisions = []\navg_ndcg = []\nrelevance_score_list = []\n\nfor index, row in df_test.iterrows():\n    expected_result = []\n    query = literal_eval(row['Test_Query'])\n    query =  \", \".join(query)\n\n    expected_id = literal_eval(row['Recipe_IDs'])\n    expected_result += [df.iloc[idx]['processed_ingredients'] for idx in expected_id]\n\n    # Use faiss_retriever to get relevant documents\n    s = ensemble_retriever.get_relevant_documents(query)\n    retriver_df =retrieve_and_filter_df_en(df, s)\n\n    # Assuming 's' is a list of items where each item is an object with a 'page_content' attribute\n    retrieved_result = [item for item in retriver_df['processed_ingredients']]\n    \n    \n    relevance_scores = [1 if i in expected_result else 0 for i in retrieved_result]\n    relevance_score_list.append(relevance_scores)\n    average_precisions.append(average_precision(relevance_scores))\n    avg_ndcg.append(ndcg_at_k(relevance_scores, 5))\n\n# Compute the Mean Reciprocal Rank\nmap_score = np.mean(average_precisions)\nmrr_score = mean_reciprocal_rank(relevance_score_list)\nndcg_score = np.mean(avg_ndcg)\n\n# Print the scores\nprint(f\"MAP Score: {map_score}\")\nprint(f\"NDCG Score: {ndcg_score}\")\nprint(f\"Mean Reciprocal Rank Score: {mrr_score}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-08T03:52:03.478171Z","iopub.execute_input":"2023-12-08T03:52:03.478568Z","iopub.status.idle":"2023-12-08T03:55:02.337793Z","shell.execute_reply.started":"2023-12-08T03:52:03.478533Z","shell.execute_reply":"2023-12-08T03:55:02.336789Z"},"trusted":true},"execution_count":99,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf74117b214420abb0ce2a730acec2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cc0b94023464391bdc02ecd1db125c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0342ef13e29843f5ab66ade6debbaa0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cc60824fc2d4e27abdfe498d5eef71a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4c03b745f5a4f7b8344f1e7f8b10c97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f5babf721c4a6c9679d87d718781fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa42063ea93d46168b426bd281d0f9e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2f0ab10f6d4c12a0f41f7634c0c9a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b38555c9d8d9480ba71e47155a7c285e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd5317b04c9842cb8c6e8f843e992f40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e864eff93414b79abd70e31109409ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9179218fdb674e20ac155c013d9acb5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc046f6c2c84896be87a96869499a12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b12594d1bc644ca6a973f6159bf47b95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdf3f3ecebc745298cf99bc96c0247a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45d572401c44de4b756902204e80231"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7802768967a4e8aafaf7f6beec36839"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf2cfde5b3c46ada005d3cdebcd3c24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c9120ea201b420781ddf8d6ecabf978"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb378e1ac9fa44e8a87fd5a2b45f840c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a42a809483fb4a46b978674738817566"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7690c677731b473c93f40ce58d453a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d437ede6ab2d406d89c6ef8927bdcd22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b63bfb3cbff4077b45685de24bef03e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd98cbf6faef494e945747d5daed4b0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d93e0a1627e4caa96be2723b714b61f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd30d818d4504a688bb6066bca43de22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bdcad2b96ce4fc6b9fffcb0720dc2fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f9fe1ce6cb949748aa31a3b48368404"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b25a96c16540aca0c8e40ca2bbf703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"693277a64bd94a548b3f7572cf3fef29"}},"metadata":{}},{"name":"stdout","text":"MAP Score: 0.48738351254480267\nNDCG Score: 0.5567851610302778\nMean Reciprocal Rank Score: 0.6462365591397847\n","output_type":"stream"}]}]}